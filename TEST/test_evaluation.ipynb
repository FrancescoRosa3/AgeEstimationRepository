{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"test_evaluation.ipynb","provenance":[],"collapsed_sections":["Qqh0o3kdlgZJ","JPBrQQY_EWLM","M37QDCiIatym","xPDvdNHtoFZ0","sh53SXOd8aHN","MW57ZASVrpUb","H1_vjOkapa7h","RDsjm1yWfwdZ","JhHQ5ZL3mjIP","Ofqto8DXs3FZ","C7SqWnxHcGwD","wO4iObgQcMKW"]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qZ2XCXLKVkEq"},"source":["# CONSEGNA GRUPPO 19\r\n","*   Demetrio Trimarco\r\n","*   Emilio Sorrentino\r\n","*   Francesco Rosa\r\n","*   Francesco Sabbarese"]},{"cell_type":"markdown","metadata":{"id":"Qqh0o3kdlgZJ"},"source":["# SETUP"]},{"cell_type":"code","metadata":{"id":"HDvCOTaG6i1i"},"source":["from google.colab import drive\r\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JPBrQQY_EWLM"},"source":["## IMPORT\n"]},{"cell_type":"code","metadata":{"id":"8aLM0-5BlgZL","executionInfo":{"status":"ok","timestamp":1610044456833,"user_tz":-60,"elapsed":20835,"user":{"displayName":"DEMETRIO TRIMARCO","photoUrl":"","userId":"14755733733602952415"}}},"source":["%load_ext tensorboard\r\n","from tensorflow import keras\r\n","%tensorflow_version 2.x\r\n","import tensorflow as tf\r\n","from keras.callbacks import TensorBoard\r\n","from datetime import datetime\r\n","from packaging import version\r\n","import os\r\n","import io\r\n","from PIL import Image\r\n","from functools import partial\r\n","import matplotlib.pyplot as plt\r\n","import numpy as np\r\n","import cv2\r\n","import json"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"-pYJSy-LlpoE"},"source":["# import vggface models\r\n","!pip install git+https://github.com/rcmalli/keras-vggface.git\r\n","!pip install keras_vggface\r\n","!pip install keras_applications\r\n","from keras_vggface.vggface import VGGFace\r\n","import keras_vggface.utils"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M37QDCiIatym"},"source":["## VARIABLES"]},{"cell_type":"code","metadata":{"id":"LcwHkgAXEaPW","executionInfo":{"status":"ok","timestamp":1610044465933,"user_tz":-60,"elapsed":29931,"user":{"displayName":"DEMETRIO TRIMARCO","photoUrl":"","userId":"14755733733602952415"}}},"source":["# MODEL_PATH = \"/content/gdrive/MyDrive/CONSEGNA/TEST/----------\"\n","MODEL_PATH = \"/content/gdrive/MyDrive/CONSEGNA/TEST/model_group_19.h5\"\n","\n","TEST_SIZE = 169396\n","eval_tfrecord_file_name = \"/content/gdrive/MyDrive/CONSEGNA/DATASETS/test_set.tfrecord\"\n","\n","BATCH_SIZE = 64"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xPDvdNHtoFZ0"},"source":["# RUN EVALUATION"]},{"cell_type":"markdown","metadata":{"id":"sh53SXOd8aHN"},"source":["## Parse tfrecord function"]},{"cell_type":"code","metadata":{"id":"8Do-QasxoQkD","executionInfo":{"status":"ok","timestamp":1610046079979,"user_tz":-60,"elapsed":796,"user":{"displayName":"DEMETRIO TRIMARCO","photoUrl":"","userId":"14755733733602952415"}}},"source":["def decode_image(image):\r\n","  image = tf.image.decode_jpeg(image, channels=3)\r\n","  image = tf.image.resize(image, [240, 240])\r\n","  image = tf.cast(image, tf.uint8)\r\n","  return image\r\n","\r\n","def conv_normalize(image):\r\n","  return keras_vggface.utils.preprocess_input(image, 'channels_last', version=2)\r\n","\r\n","def conv_BGR2RGB(image):\r\n","  return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\r\n","\r\n","def conv_RGB2BGR(image):\r\n","  return cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\r\n","\r\n","# parse tfrecord samples\r\n","def read_tfrecord(example):\r\n","    features = (\r\n","        {\r\n","          \"image\": tf.io.FixedLenFeature([], dtype=tf.string),\r\n","          \"filename\": tf.io.FixedLenFeature([], dtype=tf.string)\r\n","        }\r\n","    )\r\n","\r\n","    example = tf.io.parse_single_example(example, features)\r\n","\r\n","    image = example[\"image\"]\r\n","    \r\n","    image = decode_image(image) # the decoded image has BGR channels\r\n","    \r\n","    image = tf.numpy_function(conv_BGR2RGB, [image], tf.uint8)\r\n","    image = tf.cast(image, dtype=tf.float32)\r\n","    # conv_normalize needs RGB images as input and returns BGR images as output\r\n","    image = tf.numpy_function(conv_normalize, [image], tf.float32)\r\n","\r\n","    filename = example[\"filename\"]\r\n","    \r\n","    return image, filename"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MW57ZASVrpUb"},"source":["## Loading dataset function"]},{"cell_type":"code","metadata":{"id":"XU6emYLgoQkE","executionInfo":{"status":"ok","timestamp":1610046081028,"user_tz":-60,"elapsed":648,"user":{"displayName":"DEMETRIO TRIMARCO","photoUrl":"","userId":"14755733733602952415"}}},"source":["# Load a dataset and parse the samples\r\n","def load_dataset(tfrecord_filename):\r\n","    dataset = tf.data.TFRecordDataset(tfrecord_filename)\r\n","    dataset = dataset.map(read_tfrecord)\r\n","    return dataset"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H1_vjOkapa7h"},"source":["## Pipeline creation function"]},{"cell_type":"code","metadata":{"id":"8dVS5d5EuW3P","executionInfo":{"status":"ok","timestamp":1610046081758,"user_tz":-60,"elapsed":387,"user":{"displayName":"DEMETRIO TRIMARCO","photoUrl":"","userId":"14755733733602952415"}}},"source":["def apply_pipeline(path, labeled = True):\r\n","    dataset = load_dataset(path)\r\n","    dataset = dataset.batch(BATCH_SIZE)\r\n","    return dataset"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RDsjm1yWfwdZ"},"source":["## Load model"]},{"cell_type":"code","metadata":{"id":"qXzbC5ASfMEs","executionInfo":{"status":"ok","timestamp":1610046091502,"user_tz":-60,"elapsed":9321,"user":{"displayName":"DEMETRIO TRIMARCO","photoUrl":"","userId":"14755733733602952415"}}},"source":["# Recreate the exact same model, including its weights and the optimizer\r\n","model = tf.keras.models.load_model(MODEL_PATH, compile = False)\r\n","model.compile(\r\n","          optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9),\r\n","          loss = tf.keras.losses.MeanAbsoluteError()\r\n",")\r\n","# Show the model architecture\r\n","# model.summary()"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JhHQ5ZL3mjIP"},"source":["## Predict"]},{"cell_type":"code","metadata":{"id":"lqcdz03LmgEM"},"source":["eval_dataset = apply_pipeline(eval_tfrecord_file_name)\r\n","\r\n","y_pred = model.predict(eval_dataset,\r\n","    verbose = 1,\r\n","    batch_size = BATCH_SIZE,\r\n","    steps = TEST_SIZE/BATCH_SIZE,\r\n","    workers = 4,\r\n","    use_multiprocessing = True\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"76_7ASXg_E_Y","executionInfo":{"status":"ok","timestamp":1610046624355,"user_tz":-60,"elapsed":541119,"user":{"displayName":"DEMETRIO TRIMARCO","photoUrl":"","userId":"14755733733602952415"}}},"source":["y_pred_scalar = []\r\n","for y_hat in y_pred:\r\n","  y_pred_scalar.append(round(y_hat[0]))\r\n","y_pred_scalar = np.array(y_pred_scalar).T"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"dPPwOkTiBUer"},"source":["print(y_pred_scalar)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iJbScmeOByth"},"source":["from csv import reader\r\n","\r\n","with open('/content/gdrive/MyDrive/CONSEGNA/TEST/test_filenames.csv', 'r') as read_obj:\r\n","    csv_reader = reader(read_obj)\r\n","    i = 0\r\n","    for row in csv_reader:\r\n","      if y_pred_scalar[i] <= 18:\r\n","        print(row[0] + \" - \" + str(y_pred_scalar[i]))\r\n","      i = i + 1\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ofqto8DXs3FZ"},"source":["## Result CSV creation"]},{"cell_type":"markdown","metadata":{"id":"C7SqWnxHcGwD"},"source":["### Creation filename csv"]},{"cell_type":"code","metadata":{"id":"zcFCUGaTM968"},"source":["import csv\r\n","\r\n","dataset = load_dataset(eval_tfrecord_file_name)\r\n","with open('test_filenames.csv', mode='w') as csvfile:\r\n","  out_csv = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\r\n","  cnt = 0\r\n","  for _, filename in dataset:\r\n","    print(cnt)\r\n","    cnt = cnt + 1\r\n","    filename = str(filename.numpy()).split(\"'\")[1]\r\n","    out_csv.writerow([filename])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wO4iObgQcMKW"},"source":["### Creation result csv"]},{"cell_type":"code","metadata":{"id":"HjBuysfJNx1O"},"source":["import csv\r\n","\r\n","filenames = []\r\n","with open('/content/gdrive/MyDrive/CONSEGNA/TEST/test_filenames.csv', 'r') as csvinput:\r\n","  reader = csv.reader(csvinput)\r\n","  for row in reader:\r\n","    filenames.append(row)\r\n","print(\"filenames acquired\")\r\n","\r\n","with open('/content/gdrive/MyDrive/CONSEGNA/TEST/GROUP_19.csv', 'w') as csvoutput:\r\n","  out_csv = csv.writer(csvoutput, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\r\n","  i = 0\r\n","  for filename in filenames:\r\n","    print(i)\r\n","    out_csv.writerow([filename[0], y_pred_scalar[i]])\r\n","    i = i + 1\r\n","print(\"csv file results created\")"],"execution_count":null,"outputs":[]}]}