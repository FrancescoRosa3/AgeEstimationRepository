{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"model_evaluation_on_subset2_validation.ipynb","provenance":[],"collapsed_sections":["Qqh0o3kdlgZJ","JPBrQQY_EWLM","M37QDCiIatym","xPDvdNHtoFZ0","pKB4AeyZyOpw","sh53SXOd8aHN","MW57ZASVrpUb","H1_vjOkapa7h","RDsjm1yWfwdZ","JhHQ5ZL3mjIP"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qZ2XCXLKVkEq"},"source":["# CONSEGNA GRUPPO 19\r\n","*   Demetrio Trimarco\r\n","*   Emilio Sorrentino\r\n","*   Francesco Rosa\r\n","*   Francesco Sabbarese"]},{"cell_type":"markdown","metadata":{"id":"Qqh0o3kdlgZJ"},"source":["# SETUP"]},{"cell_type":"code","metadata":{"id":"HDvCOTaG6i1i"},"source":["from google.colab import drive\r\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JPBrQQY_EWLM"},"source":["## IMPORT\n"]},{"cell_type":"code","metadata":{"id":"8aLM0-5BlgZL"},"source":["%load_ext tensorboard\r\n","from tensorflow import keras\r\n","%tensorflow_version 2.x\r\n","import tensorflow as tf\r\n","from keras.callbacks import TensorBoard\r\n","from datetime import datetime\r\n","from packaging import version\r\n","import os\r\n","import io\r\n","from PIL import Image\r\n","from functools import partial\r\n","import matplotlib.pyplot as plt\r\n","import numpy as np\r\n","import cv2\r\n","import json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-pYJSy-LlpoE"},"source":["# import vggface models\r\n","!pip install git+https://github.com/rcmalli/keras-vggface.git\r\n","!pip install keras_vggface\r\n","!pip install keras_applications\r\n","from keras_vggface.vggface import VGGFace\r\n","import keras_vggface.utils"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M37QDCiIatym"},"source":["## VARIABLES"]},{"cell_type":"code","metadata":{"id":"LcwHkgAXEaPW"},"source":["# MODEL_PATH = \"/content/gdrive/MyDrive/CONSEGNA/TEST/----------\"\n","MODEL_PATH = \"/content/gdrive/MyDrive/CONSEGNA/TEST/model_group_19.h5\"\n","\n","EVALUATION_SIZE = 140173\n","eval_tfrecord_file_name = \"/content/gdrive/MyDrive/CONSEGNA/DATASETS/SUBSET_2_val.tfrecord\"\n","\n","BATCH_SIZE = 64"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xPDvdNHtoFZ0"},"source":["# RUN EVALUATION"]},{"cell_type":"markdown","metadata":{"id":"pKB4AeyZyOpw"},"source":["## Label dictionary creation"]},{"cell_type":"code","metadata":{"id":"dzDTpuqXyOyh"},"source":["from csv import reader\r\n","\r\n","def create_example_dictionary():\r\n","    train_dictionary = {}\r\n","    with open('/content/gdrive/MyDrive/CONSEGNA/DATASETS/train.age_detected.csv', 'r') as read_obj:\r\n","        print(\"Example label opened\")\r\n","        csv_reader = reader(read_obj)\r\n","        for row in csv_reader:\r\n","            # print(row[0] + \" \" + row[-1])\r\n","            age = str(row[-1])\r\n","            train_dictionary[row[0]] = age\r\n","\r\n","    return train_dictionary\r\n","\r\n","example_dictionary = create_example_dictionary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sh53SXOd8aHN"},"source":["## Parse tfrecord function"]},{"cell_type":"code","metadata":{"id":"8Do-QasxoQkD"},"source":["def get_age(filename):\r\n","  filename = str(filename).split(\"'\",2)[1]\r\n","  return round(float(example_dictionary[filename]))\r\n","\r\n","def decode_image(image):\r\n","  image = tf.image.decode_jpeg(image, channels=3)\r\n","  image = tf.image.resize(image, [240, 240])\r\n","  image = tf.cast(image, tf.uint8)\r\n","  return image\r\n","\r\n","def conv_normalize(image):\r\n","  return keras_vggface.utils.preprocess_input(image, 'channels_last', version=2)\r\n","\r\n","def conv_BGR2RGB(image):\r\n","  return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\r\n","\r\n","def conv_RGB2BGR(image):\r\n","  return cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\r\n","\r\n","# parse tfrecord samples\r\n","def read_tfrecord(example):\r\n","    features = (\r\n","        {\r\n","          \"image\": tf.io.FixedLenFeature([], dtype=tf.string),\r\n","          \"filename\": tf.io.FixedLenFeature([], dtype=tf.string)\r\n","        }\r\n","    )\r\n","\r\n","    example = tf.io.parse_single_example(example, features)\r\n","\r\n","    image = example[\"image\"]\r\n","    \r\n","    image = decode_image(image) # the decoded image has BGR channels\r\n","    \r\n","    image = tf.numpy_function(conv_BGR2RGB, [image], tf.uint8)\r\n","    image = tf.cast(image, dtype=tf.float32)\r\n","    # conv_normalize needs RGB images as input and returns BGR images as output\r\n","    image = tf.numpy_function(conv_normalize, [image], tf.float32)\r\n","\r\n","    filename = example[\"filename\"]\r\n","    label = tf.numpy_function(get_age, [filename], tf.int64)\r\n","\r\n","    return image, label"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MW57ZASVrpUb"},"source":["## Loading dataset function"]},{"cell_type":"code","metadata":{"id":"XU6emYLgoQkE"},"source":["# Load a dataset and parse the samples\r\n","def load_dataset(tfrecord_filename):\r\n","    dataset = tf.data.TFRecordDataset(tfrecord_filename)\r\n","    dataset = dataset.map(read_tfrecord)\r\n","    return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H1_vjOkapa7h"},"source":["## Pipeline creation function"]},{"cell_type":"code","metadata":{"id":"8dVS5d5EuW3P"},"source":["def apply_pipeline(path, labeled = True):\r\n","    dataset = load_dataset(path)\r\n","    dataset = dataset.batch(BATCH_SIZE)\r\n","    return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RDsjm1yWfwdZ"},"source":["## Load model"]},{"cell_type":"code","metadata":{"id":"qXzbC5ASfMEs"},"source":["# Recreate the exact same model, including its weights and the optimizer\r\n","model = tf.keras.models.load_model(MODEL_PATH, compile = False)\r\n","model.compile(\r\n","          optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9),\r\n","          loss = tf.keras.losses.MeanAbsoluteError()\r\n",")\r\n","# Show the model architecture\r\n","# model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JhHQ5ZL3mjIP"},"source":["## Predict"]},{"cell_type":"code","metadata":{"id":"lqcdz03LmgEM"},"source":["eval_dataset = apply_pipeline(eval_tfrecord_file_name)\r\n","\r\n","y_pred = model.predict(eval_dataset,\r\n","    verbose = 1,\r\n","    batch_size = BATCH_SIZE,\r\n","    steps = EVALUATION_SIZE/BATCH_SIZE,\r\n","    workers = 4,\r\n","    use_multiprocessing = True\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"STqR-GRfrvTN"},"source":["# Get labels from dataset\r\n","eval_dataset = load_dataset(eval_tfrecord_file_name)\r\n","tf.config.run_functions_eagerly(True)\r\n","\r\n","labels = []\r\n","for _, label in eval_dataset:\r\n","  labels.append(label.numpy())\r\n","print(\"Labels acquired\")\r\n","\r\n","# compute the rounded labels\r\n","y_pred_scalar = []\r\n","for y_hat in y_pred:\r\n","  y_pred_scalar.append(round(y_hat[0]))\r\n","y_pred_scalar = np.array(y_pred_scalar).T"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vRT9Dsshr5J1"},"source":["# compute MAE\r\n","def MAE(y_true, y_pred):\r\n","  return (np.sum(abs(y_pred - y_true)))/EVALUATION_SIZE\r\n","\r\n","MAE(np.array(labels).T, y_pred_scalar)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AAfmd9crsLJb"},"source":["# prediction matrix creation\r\n","\r\n","from sklearn.metrics import confusion_matrix \r\n","\r\n","matrix = confusion_matrix(np.array(labels).T, y_pred_scalar)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CnXtq3UOsOXy"},"source":["# plot of the confusion matrix\r\n","\r\n","import seaborn as sn\r\n","import pandas as pd\r\n","import matplotlib.pyplot as plt\r\n","\r\n","df_cm = pd.DataFrame(matrix, range(matrix.shape[0]), range(matrix.shape[0]))\r\n","plt.figure(figsize=(33,33))\r\n","sn.set(font_scale=1) # for label size\r\n","sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 7}) # font size\r\n","\r\n","plt.show()"],"execution_count":null,"outputs":[]}]}